{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89384561",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7862/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x15ba0925df0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\samsu\\anaconda3\\envs\\WebApp_Fatsai\\lib\\site-packages\\gradio\\routes.py\", line 214, in predict\n",
      "    output = await run_in_threadpool(app.launchable.process_api, body, username)\n",
      "  File \"C:\\Users\\samsu\\anaconda3\\envs\\WebApp_Fatsai\\lib\\site-packages\\starlette\\concurrency.py\", line 39, in run_in_threadpool\n",
      "    return await anyio.to_thread.run_sync(func, *args)\n",
      "  File \"C:\\Users\\samsu\\anaconda3\\envs\\WebApp_Fatsai\\lib\\site-packages\\anyio\\to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"C:\\Users\\samsu\\anaconda3\\envs\\WebApp_Fatsai\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\samsu\\anaconda3\\envs\\WebApp_Fatsai\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\samsu\\anaconda3\\envs\\WebApp_Fatsai\\lib\\site-packages\\gradio\\interface.py\", line 557, in process_api\n",
      "    prediction, durations = self.process(raw_input)\n",
      "  File \"C:\\Users\\samsu\\anaconda3\\envs\\WebApp_Fatsai\\lib\\site-packages\\gradio\\interface.py\", line 588, in process\n",
      "    predictions, durations = self.run_prediction(\n",
      "  File \"C:\\Users\\samsu\\anaconda3\\envs\\WebApp_Fatsai\\lib\\site-packages\\gradio\\interface.py\", line 517, in run_prediction\n",
      "    prediction = predict_fn(*processed_input)\n",
      "  File \"C:\\Users\\samsu\\AppData\\Local\\Temp/ipykernel_23192/4113187609.py\", line 68, in segmentation\n",
      "    print(image_seg.shape())\n",
      "TypeError: 'tuple' object is not callable\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "seed_value= 0\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(0)\n",
    "import gradio as gr\n",
    "import time\n",
    "from Image_Segmentation.model import *\n",
    "from Image_Segmentation.data import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "from keras.preprocessing.image import img_to_array,load_img\n",
    "from keras.applications.vgg16 import preprocess_input,decode_predictions\n",
    "from keras.models import load_model\n",
    "from fastai.vision import *\n",
    "import matplotlib.image as mpimg\n",
    "# Load learners and models\n",
    "learn = load_learner('Crown_Rump_Identifier/densenet121_hp_2')\n",
    "model_classification = load_model('Segmentation_Classifier/model/VGG16_model3.hdf5')\n",
    "model = load_model(\"Image_Segmentation/model/UNetModel.hdf5\", custom_objects={'dice_coef_loss': dice_coef_loss, 'dice_coef': dice_coef})\n",
    "# Data Pre-Processing function called for the U-Net model prediction\n",
    "dp = data_preprocess(test_path='Image_Segmentation/data/test',save_path='temp',\n",
    "                     test_fullscale_path='Image_Segmentation/data/test_empty',\n",
    "                     save_post_path='Image_Segmentation/data/test_result/post/post', save_roi_restored='data/roi/restored', \n",
    "                     target_rows = 256, target_cols = 256, img_type = 'jpg')\n",
    "# Find Crown and Rump Predictions\n",
    "def findCRPreds(model, image) -> None:\n",
    "    # Call prediction model\n",
    "    prediction = model.predict(image)\n",
    "    cr_locations = prediction[1]\n",
    "    coord = cr_locations[0]\n",
    "    coord1 = cr_locations[1]\n",
    "    # Scale the coordinates\n",
    "    r1 = (float(coord[0])+1)/2\n",
    "    c1 = (float(coord[1])+1)/2\n",
    "    r2 = (float(coord1[0])+1)/2\n",
    "    c2 = (float(coord1[1])+1)/2\n",
    "    r1_r = (r1 * image.size[0])\n",
    "    r2_r = (r2 * image.size[0])\n",
    "    c1_r = (c1 * image.size[1])\n",
    "    c2_r = (c2 * image.size[1])\n",
    "    location = tensor(\n",
    "      [ [float(c1_r), float(r1_r) ], \n",
    "        [float(c2_r), float(r2_r) ]  ]\n",
    "       )\n",
    "    # Plot and save the coordinates\n",
    "    img = PIL.Image.open(\"temp/segmented_image_after_mask.jpg\")\n",
    "    gray_img = img.convert(\"L\")\n",
    "    plt.imshow(gray_img, cmap='gray')\n",
    "    x, y = location.T\n",
    "    plt.scatter(x,y)\n",
    "    plt.axis('off')\n",
    "    plt.savefig('temp/my_plot.jpg',  bbox_inches='tight',pad_inches = 0)\n",
    "    im = plt.imread('temp/my_plot.jpg')\n",
    "    implot = plt.imshow(im)\n",
    "    plt.show()\n",
    "\n",
    "# Function called during the Gradio interface\n",
    "def segmentation(image):\n",
    "    # Load image for segmentation model\n",
    "    picture = image.save(\"temp/segmented.jpg\") \n",
    "    x,img_size = dp.image_normalized(\"temp/segmented.jpg\")\n",
    "    image_seg = model.predict(x)\n",
    "    name = \"segmented_image2\"\n",
    "    # Save predicted mask\n",
    "    dp.saveResult(image_seg, img_size, name.split('.')[0])\n",
    "    # Segment original image with the use of the mask\n",
    "    MaskImg = cv2.imread('temp/segmented_image2_predict.jpg', 0) \n",
    "    image_seg = cv2.imread('temp/segmented.jpg', 0) \n",
    "    bitwiseAnd = cv2.bitwise_and(image_seg, MaskImg)\n",
    "    cv2.imwrite('temp/segmented_image_after_mask.jpg',bitwiseAnd)\n",
    "    # Load segmented image\n",
    "    image1 = load_img('temp/segmented_image_after_mask.jpg', target_size=(224, 224)) \n",
    "    # Pre-process segmented image\n",
    "    image_x = img_to_array(image1)\n",
    "    image_x = np.expand_dims(image_x, axis=0)\n",
    "    image_x = tf.keras.applications.vgg16.preprocess_input(image_x, data_format=None)\n",
    "    preds = model_classification.predict(image_x)\n",
    "    # Classify predictions for classification\n",
    "    if preds[0][0]>preds[0][1]:\n",
    "        Result = 'Good Segmentation'\n",
    "    elif preds[0][1]>preds[0][0]:\n",
    "        Result = 'Bad Segmentation'\n",
    "    SegmentedImage2 = open_image('temp/segmented_image_after_mask.jpg')\n",
    "    # Predict Crown and Rump Coordinates\n",
    "    findCRPreds(learn, SegmentedImage2)\n",
    "    CrownRumpImg = load_img('temp/my_plot.jpg') \n",
    "    SegmentedImg = load_img('temp/segmented_image_after_mask.jpg')\n",
    "    # Return outputted images\n",
    "    return SegmentedImg, Result, CrownRumpImg\n",
    "# Configuration of outputs\n",
    "o1 = gr.outputs.Image(type=\"pil\", label=\"Segmented Image\")\n",
    "o2 = gr.outputs.Textbox()\n",
    "o3 = gr.outputs.Image(type=\"pil\", label=\"Crown and Rump Identified\")\n",
    "# Gradio interface\n",
    "gr.Interface(fn=segmentation, \n",
    "              inputs=gr.inputs.Image(type=\"pil\"), \n",
    "              outputs=[o1,o2,o3]).launch();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0767825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
